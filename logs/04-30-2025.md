---
date: 04-30-2025
time: 11:47:54 AM
links:
  - https://docs.anthropic.com/en/release-notes/system-prompts#feb-24th-2025
  - https://github.com/snwfdhmp/llm
  - https://www.promptingguide.ai/techniques
  - https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/
  - https://github.com/snwfdhmp/awesome-gpt-prompt-engineering
  - https://www.promptingguide.ai/techniques
tags:
  - system_prompts
  - prompt_engineering
  - claude vs gpt
---

### What did you look into?
Started to investigate *prompt engineering*. I was looking for general guidance on
creating prompts that would optimize output from models. It seems people have done A LOT
of experimenting to figure out what works best for them.

Used **Claude** for the first time. It's got a very humanistic onboarding/orientation.

### What did you find or learn?
- Anthropic [publishes it's system prompts](https://docs.anthropic.com/en/release-notes/system-prompts#feb-24th-2025)
- Found a [javascript version of llm from command line](https://github.com/snwfdhmp/llm)


There is an OVERWHELMING amount of information out there on prompt engineering (as with most things in tech), multiple sources
indicate that getting desired output involves experimentation and iteration. Doesn't seem worthwhile to dive to deep into, I'm
going to look at a few articles, ask Claude and GPT, and create my own mental model or base prompt along with some general guidelines.

### Articles/Pages Read
- https://www.promptingguide.ai/techniques
- https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/
- https://github.com/snwfdhmp/awesome-gpt-prompt-engineering
- https://www.promptingguide.ai/techniques

### Key takeaways above articles
- Account for training cut off dates (particularly important when coding because models
may not inherently have most up to date access from documentation)
- Starting off with a prototype then asking the model for help is a great way to control the flow of the conversation
- Managing the conversation (context) is critical
- Keep in mind they (the model's) are prone to be overconfident
  - **YOU MUST CHECK THEIR WORK**
- Be direct

## GPT 4o vs Claude 3.7 Sonnet - Optimal Prompt Framework
I asked the following to both models:
- https://chatgpt.com/share/681265fe-db38-8005-af03-a86cfb8320e8
- https://claude.ai/share/e6b22859-74be-48a6-83b0-6049180716cd

``` prompt
You are a helpful assistant. Provide me guidelines on how to create prompts for the most optimal output.
Keep in mind your own design, and offer guidance that will synergize with that. My end goal is to create
a reusable mental model and framework to apply to our conversations.

```

GPT gave me more preferable and specific output that I saved as prompt_cheat_sheet.md
A lot of this seems to reflect what others said in their articles.

#### Misc.
- Prior to things like Cursor, people had their own creative ways to jam their code into an LLM model 
