# learnlog-ai

**learnlog-ai** is a daily learning log built to track my ongoing exploration of artificial intelligenceâ€”particularly generative AI and large language models (LLMs). It was inspired by the curiosity sparked during the **PyData Virginia** conference and the desire to dig deeper into the space.

This project helps me stay accountable, encourages active research, and challenges me to turn unstructured exploration into structured, shareable notes.

## Summary
HN comment from [A staff engineer's journey with Claude Code (sanity.io)](https://news.ycombinator.com/item?id=45107962) in response to [this article](https://www.sanity.io/blog/first-attempt-will-be-95-garbage) that succinctly describes the majority of blogs, and articles around LLMs (As of **09-03-2025**):

> spicyusername
> I guess we're just going to be in the age of this conversation topic until everyone gets tired of talking about it.
>
> Every one of these discussions boils down to the following:
>
> - LLMs are not good at writing code on their own unless it's extremely simple or boilerplate
> 
> - LLMs can be good at helping you debug existing code
> 
> - LLMs can be good at brainstorming solutions to new problems
> 
> - The code that is written by LLMs always needs to be heavily monitored for correctness, style, and design, and then typically edited down, often to at least half its original size
> 
> - LLMs utility is high enough that it is now going to be a standard tool in the toolbox of every software engineer, but it is definitely not replacing anyone at current capability.
> 
> - New software engineers are going to suffer the most because they know how to edit the responses the least, but this was true when they wrote their own code with stack overflow.
> 
> - At senior level, sometimes using LLMs is going to save you a ton of time and sometimes it's going to waste your time. Net-net, it's probably positive, but there are definitely some horrible days where you spend too long going back and forth, when you should have just tried to solve the problem yourself.
> 

### Preferred Mental Model
A helpful assistant who will diligently do EXACTLY what you tell them to. Their memory is short, and they will often forget things so it will be your job to remind them (and keep their limitations in mind). They do a lot better when you provide them step by step instructions, and give them initial context. 

They will provide you **INCORRECT** answers with supreme confidence! So it is **IMPERATIVE** to double check their work.

If you provide them with very specific use cases, they can often quickly provide you good answers (especially boilerplate, and examples).

Overall I would say AI (LLMs) is a tool (just like the internet) that is potentially very powerful when used correctly. Although this seems like more of an art than a science at times. Just like the internet LLMs can be a huge distraction or time waster if you are not careful, so you need to be mindful of how you use them. Just like anything in programming, there are always trade offs. 

### Recap
There were diminishing returns from doing this everyday so I stopped. It still hung over my head in a weird way that I never "completed" this project. Eventually I saw the above comment from HN, and thought "Wow that's exactly how I feel". So I drop it here, and consider this closed for now.

Anyways.